# Choose machine learning model


```{r, echo=FALSE, message=FALSE}

library(tidymodels)
library(gt)

Summary <- tibble(
  Model = c("Linear regression", "Partial least squares", "Logistic regression", "Ridge regression", "Elastic net/lasso", "Support vector machines", "MARS/FDA", "K-nearest neighbors", "Random forest", "Boosted trees", "Neural networks", "LDA", "Naive Bayes", "C5.0"),
  Mode = c("regression", "regression", "classification", "regression & classification", "regression & classification", "regression & classification", "regression & classification", "regression & classification", "regression & classification", "regression & classification", "regression & classification", "classification", "classification", "classification"),
  Allows = c("no", "depends", "no", "no", "yes", "yes", "yes", "yes", "yes", "yes", "yes", "no", "yes", "yes"),
  Preprocessing = c("centering and scaling, remove near-zero predictors, remove highly correlated predictors, remove non-informative predictors", "centering and scaling, remove non-informative predictors", "centering and scaling, remove near-zero predictors, remove highly correlated predictors, remove non-informative predictors", "centering and scaling, remove near-zero predictors, remove non-informative predictors", "centering and scaling, remove near-zero predictors", "centering and scaling, remove non-informative predictors", "", "centering and scaling, remove near-zero predictors", "", "", "centering and scaling, remove near-zero predictors, remove highly correlated predictors, remove non-informative predictors", "remove near-zero predictors", "remove near-zero predictors", ""),
  Interpretable = c("high", "low", "high", "high", "high", "low", "medium", "low", "low", "low", "low", "medium", "low", "medium"),
  Feature_selection = c("no", "yes*", "no", "no", "yes", "no", "yes", "no", "depends", "yes", "no", "no", "no", "yes"),
  Tuning_parameters = c("0", "1", "0", "1", "1-2", "1-3", "1-2", "1", "0-1", "3", "2", "0-2", "0-1", "0-3"),
  Robustness_to_noise = c("low", "NA", "low", "low", "low", "low", "mid", "mid", "high", "high", "low", "low", "mid", "high"),
  Computation_time = c("fast", "fast", "fast", "fast", "fast", "slow", "mid", "fast", "slow", "slow", "slow", "fast", "mid", "low"),
  Details = c("", "", "", "", "", "", "", "", "", "", "", "", "", "")
)


Summary %>% gt() %>% cols_label(Allows = "Allows n < p", Preprocessing = "Pre-processing", Feature_selection = "Automatic feature selection", Tuning_parameters = "Number of tuning parameters", Robustness_to_noise = "Robust to predictor noise", Computation_time = "Computation time") %>% 
  tab_options(
    table.font.size = 12,
  ) %>% 
  cols_align(align = c("center"),
  columns = everything())
```

[@kuhnAppliedPredictiveModeling2013]


Common steps in model building
- Pre-processing the predictor data 
- Estimating model parameters 
- Selecting predictors for the model 
- Evaluating model performance 
- Fine tuning class prediction rules (via ROC curves, etc.)

- optimization routines (e.g., Nelderâ€“Mead simplex method = *direct methods*) can later be use to search the optimal key value (e.g., determine possible mixtures with improved compressive strength)